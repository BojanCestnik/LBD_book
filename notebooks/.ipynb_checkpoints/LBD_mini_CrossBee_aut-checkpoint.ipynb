{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossBee workflow notebook tutorial based on Python script modules for LBD\n",
    "\n",
    "CrossBee is a system that recommends bridging terms (*b-terms*) through an ensemble-based ranking method. It aids experts in uncovering hidden connections between unrelated domains. CrossBee facilitates the ranking, exploration, and investigation of these cross-domain bridging terms.\n",
    "\n",
    "<hr>\n",
    "\n",
    "[2] Juršič, M., Cestnik, B., Urbančič, T., Lavrač, N. (2012a). Cross-domain Literature Mining: Finding Bridging Concepts with CrossBee, *Proceedings of the 3rd International Conference on Computational Creativity*, 33-40.\n",
    "\n",
    "[3] Juršič, M., Cestnik, B., Urbančič, T., Lavrač, N. (2012b). Bisociative literature mining by ensemble heuristics. In M. R. Berthold (Ed.), *Bisociative Knowledge Discovery*, 338–358. Springer.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Note that **our motive** was to **re-implement parts** of the tools such as **CrossBee**, RaJoLink and OntoGen so that we can generally **repeat the results** with the tools from the past experiments, and not so much to optimize the written Python code. The emphasis was on the reader's understanding of the learning processes and visualizing the workflows in terms of the repeatability of the results obtained; the efficiency and elegance of the programming was often saved for later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and initialize `logging` library to track the execution of the scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Initialize logging with a basic configuration\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s: %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement: \n",
    "* Determine outlier documents (OntoGen)\n",
    "* Draw ROC curve (CrossBee)\n",
    "* Ensemble heuristics (CrossBee)\n",
    "\n",
    "TODO:\n",
    "* CrossBee (ROC in Ensemble, potential outliers)\n",
    "* OntoGen (potential outliers)\n",
    "* Domains:\n",
    "    - Autism - Calcineurin (RaJoLink, CrossBee)\n",
    "    - Alzheimer - Macrobiota (OntoGen, CrossBee)\n",
    "    - Migraine - Magnesium (RaJoLink - Migraine, CrossBee, OntoGen)\n",
    "    - Plant defense - Circadian rythm (???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import LBD components from the framework notebooks. The description of the individual components from the framework notebooks can be found in the respective notebooks. \n",
    "\n",
    "The purpose of the **import_ipynb** library is to enable the direct import of Jupyter notebooks as modules so that code, functions, and classes defined in one notebook can be easily reused in other notebooks or Python scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import LBD_01_data_acquisition\n",
    "import LBD_02_data_preprocessing\n",
    "import import_ipynb\n",
    "import LBD_03_feature_extraction\n",
    "import LBD_04_text_mining\n",
    "import LBD_05_results_analysis\n",
    "import LBD_06_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import additional Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the name of the domains $C$ and $A$, then load the responding text from the file. The expected file format is as follows:\n",
    "\n",
    "1. The file is encoded in Ascii (if it is in UTF-8 or other encoding, it should be converted to Ascii).\n",
    "2. Each line in the file represents one document. The words in each document are separated by spaces. The length of the individual documents may vary.\n",
    "3. The first word in each line is the **unique id**, followed by a semicolon. Normally **pmid** (pubmed id) can be used for this purpose. Or, as in this case of **autism-calcineurin** domains, simple count was used, due to historical reasons, to label the documents.\n",
    "4. The second word in each line can optionally stand for a predefined domain (or class) of the document. In this case, the second word is preceded by **!**. For example, if the file contains documents that originate from two domains, e.g. *autism* and *calcineurin*, the second word in each line is either **!autism** or **!calcineurin**.\n",
    "5. If the second word is not preceded by **!**, it will be considered the first word of the document. In this case, the document will be given the domain **!NA** (**not applicable** or **not available**).\n",
    "\n",
    "**A background story for this experiment**\n",
    "\n",
    "First, we selected *autism* and \"calcineurin\" as our domains of interest. \n",
    "\n",
    "Then we searched PubMed and collected 214 full-text documents on autism from the decade before 2006 in PubMed Central. After collecting the documents, we converted them from HTML and PDF format to plain text and made sure that each document was formatted consistently for further analysis. The 214 full text documents are stored in the file `input/Autism_Calcineurin.txt`.\n",
    "\n",
    "We extracted around 2000 unique terms, focusing particularly on rare terms from the fields of amino acids, peptides and proteins to assess their potential relevance to autism research. Notable rare terms such as *lactoylglutathione*, *synaptophysin* and *calcium channels* appeared in our dataset.\n",
    "\n",
    "The selected rare terms *lactoylglutathione*, *synaptophysin* and *calcium channels* prompted our team's autism expert to specifically investigate their associations with *calcineurin* (as it appeared as a joint term in all literatures of the selected rare terms). *Calcineurin* is a protein phosphatase with a high prevalence in the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#domainName = 'Migraine-Magnesium'\n",
    "#fileName = 'input/Magnesium_Migraine_before1988.txt'\n",
    "#lines = LBD_01_data_acquisition.load_data_from_file(fileName)\n",
    "#lines[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 11:13:03: INFO - Loaded 15243 lines from \"input/Autism_Calcineurin.txt\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1: !Autism The basis for the need for improved training and collaboration models in the field of autism is supported through historical background and literature in related fields. Ultimately, training specific to autism spectrum disorders and related evidence-based practices is proposed as necessary for all care providers having influence on programming related to this special population. It is also posited that the most effective avenue for training is through models incorporating more intensive and interactive training processes such as hands-on learning activities with opportunities for coaching, modeling, practice and feedback. Effective collaboration across systems (including home, medical, educational, and community settings) is emphasized to facilitate consistency in implementation of strategies for ultimate program success.\\n',\n",
       " '2: !Autism Children diagnosed with autism or autism spectrum disorders (ASD) are more likely than other children to exhibit behaviors characteristic of a feeding or sleeping disorder. Parents of children with these disorders may be extremely concerned about the health and safety of their child. Sleeping and feeding problems can cause a great deal of stress to parents and other family members. Behavioral assessment and treatment procedures have been developed to address behavior problems related to sleeping and feeding disorders. This article reviews the literature about assessment and treatment, and provides recommendations regarding services to family members of individuals diagnosed with ASD and feeding or sleeping disorders.\\n',\n",
       " '3: !Autism Self-injurious behaviors (SIB) are common in individuals who have autism and related developmental disabilities. When an individual engages in SIB, these behaviors frequently become the primary treatment target because of the potential for injury. A thorough behavioral assessment aimed at determining the function of the behaviors is the first step to developing a treatment plan. This article presents a brief background of SIB and a discussion of the behavioral assessment and treatment of these behaviors to familiarize readers with the behavioral perspective on SIB in individuals who have autism and other developmental disabilities.\\n',\n",
       " '4: !Autism Social skill deficits are a pervasive and enduring feature of autism spectrum disorders (ASD). As such, social skills training (SST) should be a critical component of programming for youth with ASD. A number of SST strategies exist, including those employing social stories, video modeling interventions, social problem solving, pivotal response training, scripting procedures, computer-based interventions, priming procedures, prompting procedures, and self-monitoring. This article summarizes each intervention strategy and provides results from several research studies. Social skills assessment is a crucial first step to SST, and a number of assessment measures are described. Meta-analytic reviews of the research provide further recommendations for successful SST programs.\\n',\n",
       " '5: !Autism Children with autism benefit from intensive, early intervention that focuses on increasing the frequency, form, and function of communicative acts. Available evidence shows that highly structured behavioral methods have important positive consequences for these children, particularly in eliciting first words. However, the limitation of these methods in maintenance and generalization of skills suggests that many children with autism will need to have these methods supplemented with less adult-directed activities to increase communicative initiation and carry over learned skills to new settings and communication partners. Providing opportunities for mediated peer interactions with trained peers in natural settings seems to be especially important in maximizing the effects of this intervention.\\n',\n",
       " '6: !Autism The treatment of individuals with autism is associated with fad, controversial, unsupported, disproven, and unvalidated treatments. Eclecticism is not the best approach for treating and educating children and adolescents who have autism. Applied behavior analysis (ABA) uses methods derived from scientifically established principles of behavior and incorporates all of the factors identified by the US National Research Council as characteristic of effective interventions in educational and treatment programs for children who have autism. ABA is a primary method of treating aberrant behavior in individuals who have autism. The only interventions that have been shown to produce comprehensive, lasting results in autism have been based on the principles of ABA.\\n',\n",
       " '7: !Autism Complementary and alternative medical (CAM) treatments are commonly used for children with autism spectrum disorders. This review discusses the evidence supporting the most frequently used treatments, including categories of mind-body medicine, energy medicine, and biologically based, manipulative, and body-based practices, with the latter two treatments the most commonly selected by families. Clinical providers need to understand the evidence for efficacy (or lack thereof) and potential side effects. Some CAM practices have evidence to reject their use, such as secretin, whereas others have emerging evidence to support their use, such as melatonin. Most treatments have not been adequately studied and do not have evidence to support their use.\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domainName = 'Autism-Calcineurin'\n",
    "fileName = 'input/Autism_Calcineurin.txt'\n",
    "lines = LBD_01_data_acquisition.load_data_from_file(fileName)\n",
    "lines[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"9363: !Autism A report of two years' operation of a day-treatment center for autistic children is given. A brief historical review and a capsule summary regarding current concepts on autism are presented. The educational and treatment programs at the center are described, and two case vignettes illustrate the progress of the children. Highlights from group counseling sessions with the mothers of autistic children reveal the conflicts with which parents of disturbed children must deal. The two-year experience indicates that the identification of autism at an early age is crucial and that a day-treatment facility has much to offer the psychotic child and his parents.\\n\",\n",
       " '9364: !Autism The original papers by Kanner stressed the significance of psychogenic etiology rather than the possibility of an organic brain damage. In accord with recent literature the authors find in children suffering from this disturbance, who have been observed for several years, syndromes showing a certain degree of organic brain damage possibly of perinatal origin. EEG examination in all children shows more or less an obvious electric deviation with an indefinite maximum of slow activity in temporal areas. On the basis of observation of these children during their adolescence the authors press the work hypothesis that some adults with marked traits of autism diagnosed schizophrenia simplex represent only an adult variant of early infantile autism.\\n',\n",
       " '9365: !Autism The majority of normal children will have developed some speech by the age of two years. Significant delay in speech development may be the result of (1) deafness, (2) mental retardation, (3) faulty innervation of the speech organs, (4) aphasia, (5) autism, (6) a family trait, (7) hospitalism, (8) parental neurosis, or (9) some combination of these factors. Each nonspeaking child needs an individually planned study for precise diagnosis and recommendation for treatment.\\n',\n",
       " '9366: !Calcineurin Alzheimer Disease (AD) is a terminal age-associated dementia characterized by early synaptic dysfunction and late neurodegeneration. While the presence of plaques of fibrillar aggregates of the amyloid beta peptide (Abeta) is a signature of AD, evidence suggests that the pre-plaque small oligomeric Abeta promotes both synaptic dysfunction and neuronal death. We found that young Tg2576 transgenic mice, which accumulate Abeta and develop cognitive impairments prior to plaque deposition, have high CNS activity of calcineurin (CaN), a phosphatase involved in negative regulation of memory function via inactivation of the transcription factor CREB, and display CaN-dependent memory deficits. These results thus suggested the involvement of pre-fibrillary forms of Abeta. To investigate this issue, we compared the effect of monomeric, oligomeric and fibrillar Abeta on CaN activity, CaN-dependent pCREB and pBAD levels and cell death in SY5Y cells and in rat brain slices and determined the role of CaN on CREB phosphorylation in the CNS of Tg2576 mice. Our results show that oligomeric Abeta specifically induces CaN activity and promotes CaN-dependent CREB and BAD dephosphorylation and cell death. Furthermore, Tg2576 mice display Abeta oligomers and reduced pCREB in the CNS, which is normalized by CaN inhibition. These findings suggest a role for CaN in mediating effects of oligomeric Abeta on neural cells. Since elevated CaN levels have been reported in the CNS of cognitively impaired aged rodents, our results further suggest that abnormal CaN hyper-activity may be a common event exacerbating the cognitive and neurodegenerative impact of oligomeric Abeta in the ageing CNS.\\n',\n",
       " '9367: !Calcineurin Activation of the sarcolemmal Na(+)/H(+) exchanger (NHE)1 is increasingly documented as a process involved in cardiac hypertrophy and heart failure. However, whether NHE1 activation alone is sufficient to induce such remodeling remains unknown. We generated transgenic mice that overexpress a human NHE1 with high activity in hearts. The hearts of these mice developed cardiac hypertrophy, contractile dysfunction, and heart failure. In isolated transgenic myocytes, intracellular pH was elevated in Hepes buffer but not in physiological bicarbonate buffer, yet intracellular Na(+) concentrations were higher under both conditions. In addition, both diastolic and systolic Ca(2+) levels were increased as a consequence of Na(+)-induced Ca(2+) overload; this was accompanied by enhanced sarcoplasmic reticulum Ca(2+) loading via Ca(2+)/calmodulin-dependent protein kinase (CaMK)II-dependent phosphorylation of phospholamban. Negative force-frequency dependence was observed with preservation of high Ca(2+), suggesting a decrease in myofibril Ca(2+) sensitivity. Furthermore, the Ca(2+)-dependent prohypertrophic molecules calcineurin and CaMKII were highly activated in transgenic hearts. These effects observed in vivo and in vitro were largely prevented by the NHE1 inhibitor cariporide. Interestingly, overexpression of NHE1 in neonatal rat ventricular myocytes induced cariporide-sensitive nuclear translocation of NFAT (nuclear factor of activated T cells) and nuclear export of histone deacetylase 4, suggesting that increased Na(+)/H(+) exchange activity can alter hypertrophy-associated gene expression. However, in transgenic myocytes, contrary to exclusive translocation of histone deacetylase 4, NFAT only partially translocated to nucleus, possibly because of marked activation of p38, a negative regulator of NFAT signaling. We conclude that activation of NHE1 is sufficient to initiate cardiac hypertrophy and heart failure mainly through activation of CaMKII-histone deacetylase pathway. \\n',\n",
       " '9368: !Calcineurin Paracoccidioides brasiliensis is a dimorphic fungus that causes paracoccidioidomycosis, the most prevalent human deep mycosis in Latin America. The dimorphic transition from mycelium to yeast (M-Y) is triggered by temperature shift from 25 degrees C to 37 degrees C and is critical for pathogenicity. Intracellular Ca(2+) levels increased in hypha immediately after temperature-induced dimorphism. Chelation of Ca(2+) with extracellular (EGTA) or intracellular (BAPTA) calcium chelators inhibited temperature induced dimorphism whereas addition of extracellular Ca(2+) accelerated dimorphism. The calcineurin inhibitor cyclosporin A (CsA), but not tacrolimus (FK506), effectively decreased cell growth, halted the M-Y transition that is associated with virulence, and caused aberrant growth morphologies for all forms of P. brasiliensis. The difference between CsA and FK506 was ascribed by the higher levels of cyclophilins contrasted to FKBPs, the intracellular drug targets required for calcineurin suppression. Chronic exposure to CsA abolished intracellular Ca(2+) homeostasis. Chronic exposure to CsA decreased mRNA transcription of the CCH1 gene for plasma membrane Ca(2+) channel in yeast-form cells. CsA had no detectable effect on MDR efflux pumps, while the effect of FK506 on rhodamine excretion was not correlated with transition to yeast-form. In this study we present evidence that Ca(2+)/calmodulin-dependent phosphatase calcineurin controls hyphal and yeast morphology, M-Y dimorphism, growth and Ca(2+) homeostasis in P. brasiliensis and that CsA is an effective chemical block for thermodimorphism in this organism. The effects of calcineurin inhibitors on P. brasiliensis reinforce the therapeutical potential of these drugs in a combinatory approach with antifungal drugs to treat endemic paracoccidioidomycosis.\\n',\n",
       " '9369: !Calcineurin Advanced glycation endproducts (AGEs) are proteins that accumulate in the plasma of diabetics as a result of increased glucose concentrations and are closely linked with vascular disease. The mechanisms involved are still not clear. The aim of this study was to investigate whether AGE-induced changes in calcium (Ca(2+)) homeostasis could contribute to these mechanisms. Cultured porcine coronary artery vascular smooth muscle (VSM) cells were preincubated with glycated albumin for 96h. The sphingosine 1-phosphate (S1P)-induced intracellular Ca(2+) increase, although not increased in amplitude, was significantly prolonged in cells preincubated with glycated albumin. Intracellular Ca(2+) imaging and electrophysiological recording of ion channel currents following release of caged Ca(2+) indicated that this prolonged Ca(2+) rise occurred predominantly via changes in Ca(2+)-induced Ca(2+) release. Preincubation with glycated albumin also resulted in a threefold increase in expression of the receptor for AGE. As a consequence of the prolonged intracellular Ca(2+) rise following preincubation with glycated albumin, the S1P-induced activation of the Ca(2+)-dependent phosphatase, calcineurin (CaN) was increased. This resulted in increased S1P-induced activation of the Ca(2+)-dependent transcription factor, nuclear factor of activated T cells (NFATc). BrdU incorporation in VSM cells was increased in cells preincubated with glycated albumin and was inhibited by the CaN inhibitor, cyclosporin A. In conclusion, AGE can induce VSM proliferation via a prolonged agonist-induced Ca(2+) increase leading to increased activation of CaN and subsequently NFATc. This mechanism may contribute to pathogenesis of vascular disease in diabetes mellitus.\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[9362:9369]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15237: !Calcineurin Hydrophobic interaction chromatography is employed to determine if calmodulin might associate with its target enzymes such as cyclic nucleotide phosphodiesterase and calcineurin through its Ca2+-induced hydrophobic binding region. The majority of protein in a bovine brain extract that binds to a calmodulin-Sepharose affinity column also is observed to bind in a metal ion-independent manner to phenyl-Sepharose through hydrophobic interactions. Cyclic nucleotide phosphodiesterase activity that is bound to phenyl-Sepharose can be resolved into two activity peaks; one peak of activity is eluted with low ionic strength buffer, while the second peak eluted with an ethylene glycol gradient. Calcineurin bound tightly to the phenyl-Sepharose column and could only be eluted with 8 M urea. Increasing ethylene glycol concentrations in the reaction mixture selectively inhibited the ability of calmodulin to stimulate phosphodiesterase activity, suggesting that hydrophobic interaction is required for activation. Comparison of the proteins which are bound to and eluted from phenyl- and calmodulin-Sepharose affinity columns indicates that chromatography involving calmodulin-Sepharose resembles hydrophobic interaction chromatography with charged ligands. In this type of interaction, hydrophobic binding either is reinforced by electrostatic attractions or opposed by electrostatic repulsions to create a degree of specificity in the binding of calmodulin to certain proteins with accessible hydrophobic regions. \\n',\n",
       " '15238: !Calcineurin The NH2-terminal blocking group of the Ca2+-binding B-subunit of calcineurin (protein phosphatase-2B) has been identified as myristic acid by fast atom bombardment mass spectrometry and gas chromatography. The sequence, myristyl-Gly-Asn-Glu-Ala-, is very similar to that of the catalytic subunit of cyclic AMP-dependent protein kinase, the only other protein known to contain this fatty acid. This finding, and the elution of all myristyl peptides at 57% acetonitrile on reverse phase HPLC, may facilitate the identification of other proteins with this blocking group.\\n',\n",
       " \"15239: !Calcineurin A protein has been purified from human brain that appears to be the human equivalent of bovine 14-3-3 protein. On polyacrylamide gel electrophoresis the protein migrates as a faster major component, termed 14-3-3-2 protein, and a slower minor component, termed 14-3-3-1 protein, which consists of approximately 12% of the total protein. Both 14-3-3-1 and 14-3-3-2 have a native molecular weight of approximately 67,000. 14-3-3-2 appears to have the subunit composition alpha beta; 14-3-3-1 has the composition beta'beta'. Peptide mapping with Staphylococcus aureus V8 proteinase shows that alpha and beta subunits are unrelated but the beta and beta' subunits show some common peptides. Immunoperoxidase labelling shows that 14-3-3 is localised in neurones in the human cerebral cortex. 14-3-3 shows no enolase, creatine kinase, triose phosphate isomerase, ATPase, cyclic nucleotide-dependent protein kinase, or purine nucleoside phosphorylase activity. 14-3-3 does not bind calcium and does not appear to be related to calmodulin, calcineurin, tubulin, neurofilament proteins, clathrin-associated proteins, or tropomyosin. The functional significance of this neuronal protein remains obscure. \\n\",\n",
       " '15240: !Calcineurin Terbium, a trivalent lanthanide, effectively substituted for Ca2+ in calmodulin as judged by several criteria: intrinsic fluorescence spectra, altered mobilities on polyacrylamide gel electrophoresis, formation of a stable complex with troponin I or calcineurin, and stimulation of phosphodiesterase. Calmodulin harbors four Ca2+ binding domains; domains I and II contain no tyrosine, whereas domains III and IV each have one tyrosine. The binding of Tb3+ to calmodulin was followed by the increase of Tb3+ fluorescence at 545 nm upon binding to calmodulin. This fluorescence was elicited either by exciting Tb3+ directly at 222 nm or by exciting the calmodulin tyrosine at 280 nm with resulting energy transfer from tyrosine to Tb3+. Fluorescence generated by direct excitation measures binding of Tb3+ to any of the Ca2+ binding domains, whereas energy transfer through indirect excitation is effective only when Tb3+ is within 5 A of tyrosine, indicating that Tb3+ necessarily occupies a Ca2+ binding domain that contains tyrosine. A judicious use of the direct and indirect excitation could reveal the sequence of fill of the binding domains. Our results suggest these domains are filled in the following sequence: 1) domain I or II; 2) domains III and IV; and 3) domain II or I that has not been filled initially.\\n',\n",
       " '15241: !Calcineurin Myosin light chain kinase and a fraction of type II cAMP-dependent protein kinase have been partially purified from bovine brain by affinity chromatography on calmodulin-Sepharose. The myosin kinase was purified approximately 3700-fold and has an estimated molecular weight of 130,000 +/- 10,000 by sodium dodecyl sulfate gel electrophoresis. A fraction of soluble cAMP-dependent protein kinase also bound to calmodulin-Sepharose and was purified 2300-fold. A fraction of this cAMP-dependent protein kinase after purification by glycerol gradient centrifugation was shown to contain the two subunits of calcineurin, a major calmodulin-binding protein in brain, and the two subunits of type II cAMP-dependent protein kinase in a ratio of 1:1:2:2. Its sedimentation coefficient was 8.1 S and 9.0 S when centrifuged in the absence or presence of calmodulin, suggesting the formation of a complex between calmodulin and protein kinase. Our results suggest the possibility that calcineurin may be involved in the interaction between the protein kinase and calmodulin. Furthermore, our studies imply that the regulatory subunit of the cAMP-dependent protein kinase, but not the catalytic subunit, is the site of interaction with calmodulin since the catalytic subunit of protein kinase was partially resolved from the complex by cAMP.\\n',\n",
       " '15242: !Calcineurin Calmodulin is a ubiquitous, multifunctional, Ca2+-dependent regulatory protein, controlling a wide variety of Ca2+-mediated reactions. The versatility of calmodulin raises the question of how it exerts specificity at the molecular level. Cyclic nucleotide phosphodiesterase consists of multiple forms, one of which requires calmodulin for full activity. Calcineurin, a calmodulin-binding protein, inhibits the calmodulin-stimulated phosphodiesterase activity by competing with the enzyme for calmodulin. In this report, we present experiments which indicate that, although calcineurin potentially inhibits calmodulin-supported enzyme activity, its effectiveness as an inhibitor depends on the level of cAMP. In the presence of elevated levels of cAMP, the affinity of calmodulin for phosphodiesterase increased markedly, but that for calcineurin was not altered. Thus, the enzyme became relatively refractory to inhibition by calcineurin. This finding suggests that an increase of cellular cAMP could lead to a condition favorable to its own hydrolysis and that this phenomenon might represent an example of molecular specificity in calmodulin-regulated reactions.\\n',\n",
       " '15243: !Calcineurin The inhibitory protein that binds calmodulin and thus prevents activation of several Ca2+-dependent enzymes by calmodulin is shown to also bind four Ca2+ per mol of protein with high affinity (Kd less than or equal to 10(-6) M). On the basis of its Ca2+- binding properties and its localization to nervous tissue, the inhibitory protein is now called  \"calcineurin. \" Calcineurin is composed of two subunits: calcineurin A (61,000 Mr) which interacts with calmodulin in a Ca2+-dependent fashion, and calcineurin B (15,000 Mr) which binds Ca2+. The interaction of calcineurin A with calcineurin B is independent of Ca2+ or Mg2+. The dual interaction of calcineurin A with two different Ca2+-binding components and the high affinity of calcineurin for Ca2+ suggest a possible role for calcineurin in the regulation of free Ca2+ concentrations in the nervous system. Calcineurin may thereby modulate the release and action of neurotransmitters.\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess documents into a dictionary and extract documents as strings in a list. Might take a few minutes for longer files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 11:13:11: INFO - Text cleaning ...\n",
      "2024-09-13 11:13:14: INFO - Removing stopwords ...\n",
      "2024-09-13 11:13:15: INFO - Lematization ...\n",
      "2024-09-13 11:13:22: INFO - Keeping only longer words (>= 4 characters)...\n",
      "2024-09-13 11:13:22: INFO - Keeping only nouns ...\n"
     ]
    }
   ],
   "source": [
    "docs_dict = LBD_02_data_preprocessing.construct_dict_from_list(lines)\n",
    "\n",
    "keep_list = []\n",
    "remove_list = ['autism', 'calcineurin']\n",
    "prep_docs_dict = LBD_02_data_preprocessing.preprocess_docs_dict(\n",
    "    docs_dict, keep_list = keep_list, remove_list = remove_list, mesh_word_list = [], \\\n",
    "    cleaning = True, remove_stopwords = True, lemmatization = True, \\\n",
    "    min_word_length = 4, keep_only_nouns = True, keep_only_mesh = False, stemming = False, stem_type = None)\n",
    "\n",
    "ids_list = LBD_02_data_preprocessing.extract_ids_list(prep_docs_dict)\n",
    "prep_docs_list = LBD_02_data_preprocessing.extract_preprocessed_documents_list(prep_docs_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first dictionary items, document (pubmed) ids and preprocessed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict(itertools.islice(prep_docs_dict.items(), 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prep_docs_list[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate bag-of-words matrix from the list of preprocessed documents. Remove ngram words that occur less than *min_ngram_count* times (3 in our case) in the whole corpus of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_size = 1 # 3 for migraine\n",
    "min_df = 2\n",
    "\n",
    "# BOW representation\n",
    "word_list, bow_matrix = LBD_03_feature_extraction.create_bag_of_words(prep_docs_list, ngram_size, min_df)\n",
    "print('Number of terms in initial vocabulary with all ngrams: ', len(word_list))\n",
    "# print(word_list)\n",
    "# print(bow_matrix)\n",
    "\n",
    "# remove nterms with frequency count less than min_count_ngram from vocabulary word_list and bow_matrix\n",
    "min_count_ngram = 3 # 2 for migraine\n",
    "tmp_sum_count_docs_containing_word = LBD_03_feature_extraction.sum_count_documents_containing_each_word(word_list, bow_matrix)\n",
    "\n",
    "tmp_sum_count_word_in_docs = LBD_03_feature_extraction.sum_count_each_word_in_all_documents(word_list, bow_matrix)\n",
    "\n",
    "tmp_filter_columns = []\n",
    "for i, word in enumerate(word_list):\n",
    "    if not LBD_03_feature_extraction.word_is_nterm(word):\n",
    "        # if word in mesh_word_list:\n",
    "        tmp_filter_columns.append(i)\n",
    "    else:\n",
    "        if tmp_sum_count_word_in_docs[word] >= min_count_ngram:\n",
    "            tmp_filter_columns.append(i)\n",
    "\n",
    "tmp_filter_rows = []\n",
    "for i, id in enumerate(ids_list):\n",
    "    tmp_filter_rows.append(i)\n",
    "\n",
    "tmp_filtered_word_list, tmp_filtered_bow_matrix = LBD_03_feature_extraction.filter_matrix_columns(\n",
    "    word_list, bow_matrix, tmp_filter_rows, tmp_filter_columns)\n",
    "\n",
    "word_list = tmp_filtered_word_list\n",
    "bow_matrix = tmp_filtered_bow_matrix\n",
    "print('Number of terms in preprocessed vocabulary after removing infrequent ngrams: ', len(word_list))\n",
    "\n",
    "LBD_02_data_preprocessing.save_list_to_file(word_list, \"output/_list.txt\")\n",
    "LBD_02_data_preprocessing.save_list_to_file(prep_docs_list, \"output/_prep_list.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute margins for bag-of-word matrix. Prepare also the dictionaries of words and documents sorted according to the sum of word count in BOW matrix (*bow_matrix*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_count_docs_containing_word = LBD_03_feature_extraction.sum_count_documents_containing_each_word(word_list, bow_matrix)\n",
    "\n",
    "sum_count_word_in_docs = LBD_03_feature_extraction.sum_count_each_word_in_all_documents(word_list, bow_matrix)\n",
    "\n",
    "sum_count_words_in_doc = LBD_03_feature_extraction.sum_count_all_words_in_each_document(ids_list, bow_matrix)\n",
    "\n",
    "print('Number of documents in which each word is present: ', dict(itertools.islice(sum_count_docs_containing_word.items(), 7)))\n",
    "print('Number of occurences of each word in all documents: ', dict(itertools.islice(sum_count_word_in_docs.items(), 7)))\n",
    "print('Number of words in each document: ', dict(itertools.islice(sum_count_words_in_doc.items(), 7)))\n",
    "\n",
    "# Compute the order of rows (documents) and columns (words) in the bow matrix so that the most frequent words are in the top-left corner. \n",
    "filter_columns = LBD_02_data_preprocessing.get_index_list_of_dict1_keys(\n",
    "    LBD_02_data_preprocessing.sort_dict_by_value(sum_count_word_in_docs, reverse=True), word_list)\n",
    "filter_rows = LBD_02_data_preprocessing.get_index_list_of_dict1_keys(\n",
    "    LBD_02_data_preprocessing.sort_dict_by_value(sum_count_words_in_doc, reverse=True), ids_list) \n",
    "\n",
    "# Rearange (filter) the bow matrix according to the previously computed order.\n",
    "filtered_ids_list, filtered_word_list, filtered_bow_matrix = LBD_03_feature_extraction.filter_matrix(\n",
    "    ids_list, word_list, bow_matrix, filter_rows, filter_columns)\n",
    "print('The first few documents in the rows of the filtered bow matrix: ', filtered_ids_list[:7])\n",
    "print('The first few words in the columns of the filtered bow matrix: ', filtered_word_list[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize bag-of-words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = 0\n",
    "last_row = 20\n",
    "first_column = 0\n",
    "last_column = 15\n",
    "LBD_06_visualization.plot_bow_tfidf_matrix('Filtered bag of words', \\\n",
    "                                           filtered_bow_matrix[first_row:last_row,first_column:last_column], \\\n",
    "                                           filtered_ids_list[first_row:last_row], \\\n",
    "                                           filtered_word_list[first_column:last_column], as_int = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate tf-idf matrix from the list of preprocessed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF representation\n",
    "word_list, tfidf_matrix = LBD_03_feature_extraction.create_tfidf(prep_docs_list, ngram_size, min_df)\n",
    "print('Number of terms in initial vocabulary with all ngrams: ', len(word_list))\n",
    "# print(word_list)\n",
    "# print(tfidf_matrix)\n",
    "\n",
    "# Rearange (filter) the tfidf matrix according to the previously computed order from bow matrix.\n",
    "tmp_filtered_word_list, tmp_filtered_tfidf_matrix = LBD_03_feature_extraction.filter_matrix_columns(\n",
    "    word_list, tfidf_matrix, tmp_filter_rows, tmp_filter_columns)\n",
    "\n",
    "word_list = tmp_filtered_word_list\n",
    "tfidf_matrix = tmp_filtered_tfidf_matrix\n",
    "print('Number of terms in preprocessed vocabulary after removing infrequent ngrams: ', len(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute margins for tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_word_tfidf = LBD_03_feature_extraction.sum_count_each_word_in_all_documents(word_list, tfidf_matrix)\n",
    "max_word_tfidf = LBD_03_feature_extraction.max_tfidf_each_word_in_all_documents(word_list, tfidf_matrix)\n",
    "\n",
    "sum_doc_tfidf = LBD_03_feature_extraction.sum_count_all_words_in_each_document(ids_list, tfidf_matrix)\n",
    "max_doc_tfidf = LBD_03_feature_extraction.max_tfidf_all_words_in_each_document(ids_list, tfidf_matrix)\n",
    "\n",
    "print('Sum of tf-idf for each word: ', dict(itertools.islice(sum_word_tfidf.items(), 7)))\n",
    "print('Max of tf-idf for each word: ', dict(itertools.islice(max_word_tfidf.items(), 7)))\n",
    "\n",
    "print('Sum of tf-idf for each document: ', dict(itertools.islice(sum_doc_tfidf.items(), 7)))\n",
    "print('Max of tf-idf for each document: ', dict(itertools.islice(max_doc_tfidf.items(), 7)))\n",
    "\n",
    "# Compute the order of rows (documents) and columns (words) in the tfidf matrix so that the most important words are in the top-left corner. \n",
    "filter_columns = LBD_02_data_preprocessing.get_index_list_of_dict1_keys(\n",
    "    LBD_02_data_preprocessing.sort_dict_by_value(max_word_tfidf, reverse=True), word_list)\n",
    "filter_rows = LBD_02_data_preprocessing.get_index_list_of_dict1_keys(\n",
    "    LBD_02_data_preprocessing.sort_dict_by_value(max_doc_tfidf, reverse=True), ids_list) \n",
    "\n",
    "# Rearange (filter) the bow matrix according to the previously computed order.\n",
    "filtered_ids_list, filtered_word_list, filtered_tfidf_matrix = LBD_03_feature_extraction.filter_matrix(\n",
    "    ids_list, word_list, tfidf_matrix, filter_rows, filter_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = 0\n",
    "last_row = 20\n",
    "first_column = 0\n",
    "last_column = 25\n",
    "LBD_06_visualization.plot_bow_tfidf_matrix('Filtered TfIdf', filtered_tfidf_matrix[first_row:last_row,first_column:last_column], \\\n",
    "                                           filtered_ids_list[first_row:last_row], filtered_word_list[first_column:last_column], as_int = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of the domain names of all the documents and a list of unique domain names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_list = LBD_02_data_preprocessing.extract_domain_names_list(prep_docs_dict)\n",
    "print('Domain names for the first few documents: ', domains_list[:7])\n",
    "unique_domains_list = LBD_02_data_preprocessing.extract_unique_domain_names_list(prep_docs_dict)\n",
    "print('A list of all uniques domain names in all the documents: ', unique_domains_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate domains_bow_matrix from bow_matrix using domain_names list to add bow_matrix rows for each unique domain name into a single row\n",
    "domains_bow_matrix = np.empty((0, bow_matrix.shape[1]))\n",
    "no_documents_in_domain = {}\n",
    "for i, domain_name in enumerate(unique_domains_list):\n",
    "    domain_docs_indices = [i for i, label in enumerate(domains_list) if label == domain_name]\n",
    "    no_documents_in_domain[domain_name] = len(domain_docs_indices)\n",
    "    print(domain_docs_indices[:7])\n",
    "    tmp = (bow_matrix[domain_docs_indices,:]).sum(axis=0)\n",
    "    print(i, tmp)\n",
    "    domains_bow_matrix = np.vstack((domains_bow_matrix, tmp))\n",
    "    # Compute centroid for the current cluster\n",
    "    #centroid_x = np.mean(pca_result[cluster_docs_indices, 0])\n",
    "    #centroid_y = np.mean(pca_result[cluster_docs_indices, 1])\n",
    "print(domains_bow_matrix)\n",
    "print(no_documents_in_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_value_in_bow_matrix(bow_matrix, domain_name, word):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    line_idx = unique_domains_list.index(domain_name)\n",
    "    column_idx = word_list.index(word)\n",
    "    return(bow_matrix[line_idx, column_idx])\n",
    "\n",
    "cell_value_in_bow_matrix(domains_bow_matrix, unique_domains_list[0], word_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dictionary of words, count and max(tfidf):\")\n",
    "\n",
    "max_word_tfidf_selected = {}\n",
    "sum_word_tfidf_selected = {} ### TODO from here on ...\n",
    "for word in max_word_tfidf.keys():\n",
    "    if sum_count_docs_containing_word[word] >= 1:\n",
    "        passed = True\n",
    "        for domain_name in unique_domains_list:\n",
    "            if cell_value_in_bow_matrix(domains_bow_matrix, domain_name, word) <= 0:\n",
    "                passed = False\n",
    "        if passed:\n",
    "            max_word_tfidf_selected[word] = max_word_tfidf[word]\n",
    "         \n",
    "import itertools\n",
    "print('All the words in vocabulary: ', len(max_word_tfidf))\n",
    "print('Selected b-term candidate words: ', len(max_word_tfidf_selected), ' ', dict(itertools.islice(max_word_tfidf_selected.items(), 30)))\n",
    "\n",
    "max_word_tfidf_selected_sorted = LBD_02_data_preprocessing.sort_dict_by_value(max_word_tfidf_selected, True)\n",
    "\n",
    "print('Sorted b-term candidate words: ', len(max_word_tfidf_selected_sorted), ' ', dict(itertools.islice(max_word_tfidf_selected_sorted.items(), 30)))\n",
    "print('The first and the last sorted b-term word: ', list(max_word_tfidf_selected_sorted.items())[0], ' ', list(max_word_tfidf_selected_sorted.items())[-1])\n",
    "print('Mean value of max tf-idf values: ', np.array(list(max_word_tfidf_selected_sorted.values())).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bterms_list = list(max_word_tfidf_selected_sorted.keys())\n",
    "bterms_list_length = len(bterms_list)\n",
    "\n",
    "df = pd.DataFrame({'b-term': bterms_list, 'max tf-idf': list(max_word_tfidf_selected_sorted.values())})\n",
    "df[0:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'bcl2'\n",
    "print(name, ': ', 'position in the list of rare terms ', list(max_word_tfidf_selected_sorted.keys()).index(name), ' (', len(max_word_tfidf_selected_sorted), \\\n",
    "      '), max tfidf: ', format(max_word_tfidf_selected_sorted[name], '.3f'), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petric_bterms = [\"22q112\", \"deletion syndrome\", \"asbestos\", \"bcl2\", \"bombesin\", \"calmodulin\", \"radiation\", \\\n",
    "                 \"hypothyroxinemia\", \"synaptic\", \"synaptic plasticity\", \"type 1 diabetes\", \\\n",
    "                 \"ulcerative colitis\", \"working memory\", \\\n",
    "                 \"t17p22q21\"]\n",
    "\n",
    "petric_bterms = [\"22q112\", \"deletion\", \"syndrome\", \"asbestos\", \"bcl2\", \"bombesin\", \"calmodulin\", \"radiation\", \\\n",
    "                 \"hypothyroxinemia\", \"synaptic\", \"plasticity\", \"diabetes\", \\\n",
    "                 \"colitis\", \"work\", \"memory\", \"t17p22q21\"]\n",
    "nn = 0\n",
    "indb = []\n",
    "size = len(max_word_tfidf_selected_sorted)\n",
    "for name in petric_bterms:\n",
    "    if name in max_word_tfidf_selected_sorted.keys():\n",
    "       nn += 1\n",
    "       position = list(max_word_tfidf_selected_sorted.keys()).index(name)\n",
    "       indb.append(position)\n",
    "       print(name, ': ', 'position in the list of potential bterms ', list(max_word_tfidf_selected_sorted.keys()).index(name), ' (', len(max_word_tfidf_selected_sorted), \\\n",
    "             '), max tfidf: ', format(max_word_tfidf_selected_sorted[name], '.3f'), ' part: ', format(position/size*100, '.1f'), sep='')\n",
    "    else:\n",
    "        print('NOT:', name, 'NOT in the list.')   \n",
    "print(nn, len(petric_bterms))\n",
    "print(indb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing and changed b-terms:\n",
    "\n",
    "- maternal hypothyroxinemia -> hypothyroxinemia\n",
    "- ulcerative colitis -> colitis\n",
    "- t17p22q21 - found only in Autism documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implement selected heuristics for bterm ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = []\n",
    "for i in range(size):\n",
    "    pt.append(0)\n",
    "for i in range(len(indb)):\n",
    "    for j in range(indb[i], size):\n",
    "        pt[j] += 1\n",
    "print(pt)\n",
    "suma = 0\n",
    "part = 0\n",
    "for i in range(size):\n",
    "    print((i+1)/size*100.0, pt[i]/len(indb)*100.0)\n",
    "    part += pt[i]\n",
    "    suma += len(indb)\n",
    "print(part/suma*100.0)\n",
    "\n",
    "no_all_bterm_candidates = size\n",
    "no_swansons_bterms = len(indb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example ROC curve points (y-values), replace with the actual list of 120 numbers\n",
    "roc_points = pt\n",
    "\n",
    "# X-values for the ROC curve (0 to 120)\n",
    "x_values = np.arange(0, no_all_bterm_candidates)\n",
    "\n",
    "# Calculating the AUC for the given ROC curve using the trapezoidal rule\n",
    "auc = np.trapz(roc_points, x_values) / (no_all_bterm_candidates*no_swansons_bterms) * 100  # Normalizing by the area of the full plot\n",
    "\n",
    "# Plotting the default curve (50% AUC)\n",
    "default_x = np.array([0, no_all_bterm_candidates])\n",
    "default_y = np.array([0, no_swansons_bterms])\n",
    "plt.plot(default_x, default_y, label='Default Curve (50% AUC)', linestyle='--', color='gray')\n",
    "\n",
    "# Plotting the given ROC curve\n",
    "plt.plot(x_values, roc_points, label=f'Given ROC Curve (AUC: {auc:.2f})', color='blue')\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.xlabel('False Positive Rate (Discrete)')\n",
    "plt.ylabel('True Positive Rate (Discrete)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
