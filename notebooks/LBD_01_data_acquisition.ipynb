{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# 1. Module for data acquisition\n",
    "\n",
    "This module is responsible for capturing and loading text data from various sources such as text files, CSV files or APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict, Any\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module implements five functions for capturing text data from various sources.\n",
    "\n",
    "- load_data_from_file(file_path: str) -> List[str]:\n",
    "- load_data_from_csv(file_path: str, column_name: str) -> List[str]:\n",
    "- load_data_from_web(url: str) -> List[str]:\n",
    "- load_data_from_api(api_endpoint: str, params: Dict[str, Any]) -> List[str]:\n",
    "- load_data_from_pubmed(api_endpoint: str, params: Dict[str, Any]) -> List[str]:\n",
    "\n",
    "An additional helper function:\n",
    "\n",
    "- convert_file_to_ascii_encoding(input_filename: str, output_filename: str) -> None:\n",
    "\n",
    "can be used to convert text data from various different encodings to the Ascii encoding, which is normally supported by text processing libraries such as `nltk`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_data_from_file` function is designed to load text data from a file and return it as a list of strings, where each string represents a line from the file. This function is essential for working with textual data stored in files, which is a common scenario in data processing, machine learning, and natural language processing (NLP) tasks.\n",
    "\n",
    "**Functionality**\n",
    "\n",
    "1. *File existence check*: The function first checks if the specified file exists using the `os.path.exists()` method. If the file does not exist, it raises a `FileNotFoundError` to prevent further errors down the line.\n",
    "\n",
    "2. *Reading the file*: If the file exists, it is opened in read mode. The content of the file is read line by line using `file.readlines()`, which returns a list where each element corresponds to a line in the file.\n",
    "\n",
    "3. *Logging*: The function logs the number of lines loaded from the file using the `logging.info()` method. This is useful for tracking and debugging, especially when dealing with large files.\n",
    "\n",
    "4. *Return data*: Finally, the list of strings (each string is a line from the file) is returned for further processing.\n",
    "\n",
    "**Use**\n",
    "\n",
    "To use this function, simply pass the path of the text file you want to load:\n",
    "\n",
    "```python\n",
    "file_path = 'path/to/file.txt'\n",
    "lines = load_data_from_file(file_path)\n",
    "```\n",
    "\n",
    "This will return a list of strings, each representing a line of text from the file. You can then proceed with your data processing, whether it involves parsing, analysis, or feeding it into a machine learning model.\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- *File encoding*: The function currently opens the file with the default system encoding. If you're working with files in different encodings (like UTF-8), you may need to adjust the `open` function to handle these encodings explicitly.\n",
    "- *Error handling*: The function raises an error if the file does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Load text data from a file.\n",
    "    :param file_path: str, the path to the text file\n",
    "    :return: List[str], a list of strings containing the text data, each string is one line \n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n",
    "        \n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    logging.info(f'Loaded {len(data)} lines from \"{file_path}\".')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `convert_file_to_ascii_encoding` function is designed to read the contents of a text file and convert it to ASCII encoding. The converted content is then saved to a new file. This function is particularly useful when dealing with text that may contain non-ASCII characters, which could cause compatibility issues in certain applications or systems.\n",
    "\n",
    "In many data processing tasks, especially when dealing with legacy systems or specific text-based formats, ensuring that text data is in ASCII encoding is crucial. ASCII encoding is a character encoding standard that uses 7 bits to represent characters, which makes it highly compatible with older systems and simpler text processing pipelines.\n",
    "\n",
    "**Functionality**\n",
    "\n",
    "1. *Reading the input file*: The function first opens the specified input file in read mode and reads its entire content into a string variable.\n",
    "\n",
    "2. *Converting to ASCII*: The content is then encoded into ASCII using the `.encode('ascii', errors='replace')` method. This step replaces any non-ASCII characters with a placeholder (usually `?`), ensuring that the resulting string is pure ASCII.\n",
    "\n",
    "3. *Saving the output*: Finally, the ASCII-encoded content is written to a new file, specified by the `output_filename` parameter, ensuring that the output is in ASCII format.\n",
    "\n",
    "**Applications**\n",
    "\n",
    "- *Data standardization*: Convert various text data sources to a uniform ASCII encoding, making it easier to process and analyze them together.\n",
    "- *Legacy system integration*: Prepare text files for integration in the systems that only support ASCII encoding.\n",
    "- *Text processing*: Simplify the handling of text data by converting non-ASCII characters, which might otherwise cause errors or require complex handling.\n",
    "\n",
    "**Use**\n",
    "\n",
    "To use this function, provide the path to the input file (the file you want to convert) and the path to the output file (where you want to save the converted text):\n",
    "\n",
    "```python\n",
    "input_file = 'path/to/input_file.txt'\n",
    "output_file = 'path/to/output_file.txt'\n",
    "convert_file_to_ascii_encoding(input_file, output_file)\n",
    "```\n",
    "\n",
    "This will create a new file at `output_file` that contains the ASCII-encoded content of the `input_file`.\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- *Error handling*: The strategy `errors='replace'` replaces non-ASCII characters with a `?`. This is a safe option, but you might lose some data (e.g. special characters or diacritics). If preserving these characters is important, you should consider alternative error handling strategies such as `ignore` or `xmlcharrefreplace`.\n",
    "  \n",
    "- *Use cases for ASCII encoding*: While ASCII encoding is widely supported, it is limited in terms of characters that can be displayed. For text data containing international characters, other encodings such as UTF-8 are more suitable unless you have certain restrictions that require ASCII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file_to_ascii_encoding(input_filename: str, output_filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Read the contents of a file and save it with ASCII encoding.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_filename (str): The name of the file to be read.\n",
    "    - output_filename (str): The name of the file where the ASCII-encoded content should be saved.\n",
    "    \"\"\"\n",
    "    with open(input_filename, 'r') as file:\n",
    "        contents = file.read()\n",
    "\n",
    "    # Convert to ASCII and handle non-ASCII characters using 'replace' error strategy\n",
    "    ascii_contents = contents.encode('ascii', errors='replace').decode('ascii')\n",
    "\n",
    "    with open(output_filename, 'w', encoding='ascii') as file:\n",
    "        file.write(ascii_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_data_from_csv` function is designed to load text data from a specific column in a CSV (Comma-Separated Values) file. This function reads the CSV file, extracts the data from the specified column, and returns it as a list of strings. This is particularly useful for working with structured data where text is organized under specific columns.\n",
    "\n",
    "CSV files are one of the most common formats for storing structured data, and they are widely used across various domains such as data analysis, machine learning, and natural language processing. \n",
    "\n",
    "**How It Works**\n",
    "\n",
    "1. *File existence check*: The function first checks whether the specified CSV file exists using `os.path.exists()`. If the file is not found, a `FileNotFoundError` is raised to alert the user.\n",
    "\n",
    "2. *Reading the CSV file*: The function then reads the CSV file using the `pandas.read_csv()` function, which loads the file into a DataFrame. The file is read with UTF-8 encoding and uses `;` as the separator. This separator can be adjusted depending on the CSV file's format.\n",
    "\n",
    "3. *Column existence check*: After loading the data, the function checks whether the specified column exists in the DataFrame. If the column is not found, a `ValueError` is raised, informing the user that the column name is incorrect or doesn't exist in the file.\n",
    "\n",
    "4. *Extracting data*: If the column is found, the function extracts the data from that column and converts it to a list of strings using the `.tolist()` method. This list is then returned for further processing or analysis.\n",
    "\n",
    "**How to Use This Function**\n",
    "\n",
    "To use this function, specify the path to the CSV file and the name of the column from which you want to extract text data:\n",
    "\n",
    "```python\n",
    "file_path = 'path/to/your/data.csv'\n",
    "column_name = 'TextColumn'\n",
    "data = load_data_from_csv(file_path, column_name)\n",
    "```\n",
    "\n",
    "This will return a list of strings, where each string represents an entry from the specified column in the CSV file.\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- *CSV format*: Ensure that the separator (`sep`) used in `pd.read_csv()` matches the one used in your CSV file. The default here is `;`, which is common in some regions and formats, but many CSV files use `,` as the separator.\n",
    "\n",
    "- *Error handling*: The function includes checks for both file existence and column existence, making it robust against common user errors. However, ensure that the CSV file is well-formed and that the column names are correctly specified.\n",
    "\n",
    "- *Data types*: This function is specifically designed for loading text data. If the column contains other data types (e.g., numeric or mixed types), further processing might be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv(file_path: str, column_name: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Load text data from a specific column in a CSV file.\n",
    "    :param file_path: str, the path to the CSV file\n",
    "    :param column_name: str, the name of the column containing the text data\n",
    "    :return: List[str], a list of strings containing the text data\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n",
    "    \n",
    "    df = pd.read_csv(file_path, encoding='utf-8', sep=';')\n",
    "    \n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"The column '{column_name}' does not exist in the CSV file.\")\n",
    "        \n",
    "    data = df[column_name].tolist()\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function load_data_from_web takes a URL as input and attempts to fetch the web page using the requests.get() method. \n",
    "If the request fails, a ValueError is raised with the corresponding error message. \n",
    "Otherwise, the function proceeds to parse the HTML content of the web page using BeautifulSoup with the 'html.parser' parser.\n",
    "\n",
    "The function then finds all the paragraph elements (\\<p\\>) in the parsed HTML using the find_all() method. \n",
    "It extracts the text content of each paragraph element using the get_text() method and stores it in a list. \n",
    "Finally, the function returns the list of strings containing the text data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def load_data_from_web(url: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Scrape text data from a web page.\n",
    "    :param url: str, the URL of the web page\n",
    "    :return: List[str], a list of strings containing the text data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to load data from URL '{url}': {e}\")\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    \n",
    "    data = [paragraph.get_text() for paragraph in paragraphs]\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function load_data_from_api takes an API endpoint URL and a dictionary of parameters as input. \n",
    "It attempts to fetch data from the API using the requests.get() method with the provided parameters. \n",
    "If the request fails, a ValueError is raised with the corresponding error message. \n",
    "Otherwise, the function proceeds to parse the JSON content of the API response using the response.json() method.\n",
    "\n",
    "The function then processes the JSON data to extract the text data. \n",
    "The specific processing required depends on the structure of the JSON data returned by the API. \n",
    "In this example, it is assumed that the JSON data contains a key called \"results\" that holds a list of dictionaries, \n",
    "each containing a key \"text\" with the text data. \n",
    "The function iterates through the list of dictionaries and extracts the text data, storing it in a list. \n",
    "Finally, the function returns the list of strings containing the text data. Note that this is just an example, \n",
    "and you may need to modify the processing logic based on the specific API you are using.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def load_data_from_api(api_endpoint: str, params: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieve text data from an API endpoint.\n",
    "    :param api_endpoint: str, the URL of the API endpoint\n",
    "    :param params: Dict[str, Any], a dictionary of parameters to be sent in the API request\n",
    "    :return: List[str], a list of strings containing the text data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(api_endpoint, params=params)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to load data from API endpoint '{api_endpoint}': {e}\")\n",
    "    \n",
    "    json_data = response.json()\n",
    "\n",
    "    # Process the JSON data to extract the text data. The specific processing depends\n",
    "    # on the structure of the JSON data returned by the API. This is just an example.\n",
    "    data = [item[\"text\"] for item in json_data[\"results\"]]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function load_data_from_pubmed takes an API endpoint URL and a dictionary of parameters as input. \n",
    "It attempts to fetch data from the API using the requests.get() method with the provided parameters. \n",
    "If the request fails, a ValueError is raised with the corresponding error message. \n",
    "Otherwise, the function proceeds to parse the JSON content of the API response using the response.json() method.\n",
    "\n",
    "The function then processes the JSON data to extract the text data. \n",
    "The specific processing required depends on the structure of the JSON data returned by the API. \n",
    "In this example, it is assumed that the JSON data contains a key called \"results\" that holds a list of dictionaries, \n",
    "each containing a key \"text\" with the text data. \n",
    "The function iterates through the list of dictionaries and extracts the text data, storing it in a list. \n",
    "Finally, the function returns the list of strings containing the text data. Note that this is just an example, \n",
    "and you may need to modify the processing logic based on the specific API you are using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def load_data_from_pubmed(api_endpoint: str, params: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieve text data from PubMed.\n",
    "    :param api_endpoint: str, the URL of the API endpoint\n",
    "    :param params: Dict[str, Any], a dictionary of parameters to be sent in the API request\n",
    "    :return: List[str], a list of strings containing the text data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(api_endpoint, params=params)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to load data from pubmed '{api_endpoint}': {e}\")\n",
    "    \n",
    "    json_data = response.json()\n",
    "\n",
    "    # Process the JSON data to extract the text data. The specific processing depends\n",
    "    # on the structure of the JSON data returned by the API. This is just an example.\n",
    "    data = [item[\"text\"] for item in json_data[\"results\"]]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "if testing:\n",
    "    domainName = 'Autism'\n",
    "    fileName = 'input/214Texts.txt'\n",
    "    lines = load_data_from_file(fileName)\n",
    "    lines[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing:\n",
    "    domainName = 'Autism'\n",
    "    fileName = 'input/214Texts_store.csv'\n",
    "    lines = load_data_from_csv(fileName, 'text3')\n",
    "    lines[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing:\n",
    "    domainName = 'Autism'\n",
    "    lines = load_data_from_web('https://www.temida.si/~bojan/')\n",
    "    lines[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing:\n",
    "    domainName = 'Autism'\n",
    "    lines = load_data_from_api('https://www.temida.si/~bojan/', {})\n",
    "    lines[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing:\n",
    "    domainName = 'Autism'\n",
    "    lines = load_data_from_pubmed('https://www.temida.si/~bojan/', {})\n",
    "    lines[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
